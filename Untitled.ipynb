{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdim import global_id\n",
    "from skdim import local_id\n",
    "from _commonfuncs import get_nn\n",
    "import sklearn.utils.estimator_checks as sktest\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "utils = rpackages.importr('utils')\n",
    "#utils.install_packages('intrinsicDimension')\n",
    "#utils.install_packages('ider')\n",
    "intdimr = rpackages.importr('intrinsicDimension')\n",
    "ider   = rpackages.importr('ider')\n",
    "r_base = rpackages.importr('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.random((200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Computing DANCo calibration data for N = 500, k = 10 for dimensions 1 to 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = intdimr.pcaLocalDimEst(data,ver='FO')\n",
    "r_pca = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.dancoDimEst(data,k=10,D=10)\n",
    "r_danco = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.knnDimEst(data,k=10,ps=np.arange(11,50),M=5,gamma=2)\n",
    "r_knn = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikGlobalDimEst(data,k=20)\n",
    "r_gmle = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikLocalDimEst(data)\n",
    "r_lmle = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikPointwiseDimEst(data,k=20)\n",
    "r_pmle = np.array([i[0] for i in res])\n",
    "\n",
    "res = intdimr.pcaOtpmPointwiseDimEst(data,N=50)\n",
    "r_pcaOtpm = [np.array([i[0] for i in res]), np.array([i[1] for i in res])]\n",
    "\n",
    "\n",
    "r_corint = np.array(ider.corint(data,k1=10,k2=20))\n",
    "r_mada = np.array(ider.mada(data,local=True,k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c6f52875d6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorrInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdanco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDANCo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtwonn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwoNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_divergence_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibration_data_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dancoDimEst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fitted_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# `fit` should always return `self`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36m_dancoDimEst\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;31m#compute statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maxdim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mcal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_increaseMaxDimByOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36m_increaseMaxDimByOne\u001b[0;34m(self, dancoCalDat)\u001b[0m\n\u001b[1;32m    236\u001b[0m         dancoCalDat['calibration_data'].append(self._dancoDimEstNoCalibration(randsphere(dancoCalDat['N'], newdim,1,center=[0]*newdim)[0], \n\u001b[1;32m    237\u001b[0m                                                                              \u001b[0mdancoCalDat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                                                                              MIND_MLx_maxdim))\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mdancoCalDat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maxdim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdancoCalDat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36m_dancoDimEstNoCalibration\u001b[0;34m(self, X, D, n_jobs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0md_MIND_MLi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MIND_MLi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_MIND_MLk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_angles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mml_vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ML_VM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mmu_nu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mml_vm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36m_angles\u001b[0;34m(self, X, nbs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mnb_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc_angles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/global_id/_DANCo.py\u001b[0m in \u001b[0;36m_loc_angles\u001b[0;34m(pt, nbs)\u001b[0m\n\u001b[1;32m    179\u001b[0m        \u001b[0;31m#     vec = vec.T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mvec_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindnComb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0msc_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m#if (length(pt) == 1) {\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/skcontrib-id-estimators/skdim/_commonfuncs.py\u001b[0m in \u001b[0;36mindnComb\u001b[0;34m(NN, n)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnew_ind1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ind\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mnew_ind2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_ind\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnew_ind2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_ind2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_ind1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_ind2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corint = global_id.CorrInt().fit(data)\n",
    "danco = global_id.DANCo(D=10).fit(data)\n",
    "knn = global_id.KNN().fit(data)\n",
    "mada = global_id.Mada(local=True,k=20).fit(data)\n",
    "twonn = global_id.TwoNN().fit(data)\n",
    "\n",
    "ess = local_id.ESS().fit(data)\n",
    "fishers = local_id.FisherS().fit(data)\n",
    "lpca = local_id.lPCA().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getmembers, isfunction, isclass\n",
    "from sklearn.utils.estimator_checks import parametrize_with_checks\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.testing import (assert_equal,\n",
    "                                   assert_array_equal,\n",
    "                                   assert_array_almost_equal,\n",
    "                                   assert_raises,\n",
    "                                   assert_in,\n",
    "                                   assert_not_in,\n",
    "                                   assert_no_warnings)\n",
    "\n",
    "def test_ess(data):\n",
    "    res = intdimr.essLocalDimEst(data)\n",
    "    r_ess = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "    assert (r_ess['dim.est'] == ess.dimension_ and r_ess['ess'] == ess.essval_)\n",
    "\n",
    "def test_corint(data): \n",
    "    corint = global_id.CorrInt(k1=10,k2=20).fit(data)\n",
    "    r_corint = np.array(ider.corint(data,k1=10,k2=20))\n",
    "    assert_equal(r_corint, corint.dimension_)\n",
    "        \n",
    "def test_mada(data): \n",
    "    r_mada = np.array(ider.mada(data,local=True,k=20))\n",
    "    mada = global_id.Mada(local=True,k=20).fit(data)\n",
    "    assert_array_almost_equal(r_mada,mada.dimension_)\n",
    "\n",
    "def test_fisher_params(data):\n",
    "    try:\n",
    "        x = local_id.FisherS().fit(data)\n",
    "        x = local_id.FisherS(ConditionalNumber=2).fit(data)\n",
    "        x = local_id.FisherS(ProducePlots=True).fit(data)\n",
    "        x = local_id.FisherS(ProjectOnSphere=False).fit(data)\n",
    "        x = local_id.FisherS(ncomp=True).fit(data)\n",
    "        x = local_id.FisherS(limit_maxdim=True).fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')\n",
    "\n",
    "def test_ess_params(data):\n",
    "    try:\n",
    "        x = local_id.ESS().fit(data)\n",
    "        x = local_id.ESS(ver='b').fit(data)\n",
    "        x = local_id.ESS(d=2).fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')\n",
    "        \n",
    "def test_lPCA_params(data):\n",
    "    try:\n",
    "        x = local_id.lPCA().fit(data)\n",
    "        x = local_id.lPCA(ver='fan').fit(data)\n",
    "        x = local_id.lPCA(ver='ratio').fit(data)\n",
    "        x = local_id.lPCA(ver='maxgap').fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')\n",
    "\n",
    "def test_sklearn_compatible_estimator():\n",
    "    local_class_list = [o[1] for o in getmembers(local_id) if isclass(o[1])]\n",
    "    global_class_list = [o[1] for o in getmembers(global_id) if isclass(o[1])]\n",
    "    estimators = local_class_list+global_class_list\n",
    "\n",
    "    for estimator in estimators:\n",
    "        print(estimator)\n",
    "        check_estimator(estimator)\n",
    "\n",
    "res = intdimr.knnDimEst(data,k=10,ps=np.arange(11,50),M=1,gamma=2)\n",
    "r_knn = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "knn = global_id.KNN(k=10,ps=np.arange(11,50),M=1,gamma=2).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'local_id._ESS.ESS'>\n",
      "<class 'local_id._FisherS.FisherS'>\n",
      "<class 'local_id._TLE.TLE'>\n",
      "<class 'local_id._PCA.lPCA'>\n",
      "<class 'global_id._CorrInt.CorrInt'>\n",
      "<class 'global_id._DANCo.DANCo'>\n",
      "<class 'global_id._KNN.KNN'>\n",
      "<class 'global_id._MLE.MLE'>\n",
      "<class 'global_id._Mada.Mada'>\n",
      "<class 'global_id._TwoNN.TwoNN'>\n"
     ]
    }
   ],
   "source": [
    "test_sklearn_compatible_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from _commonfuncs import get_nn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_array, check_random_state\n",
    "\n",
    "\n",
    "class MiND(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class to calculate the intrinsic dimension of the provided data points with the Tight Locality Estimator algorithm.\n",
    "    \n",
    "    -----------\n",
    "    Attributes\n",
    "       \n",
    "    -----------\n",
    "    Returns\n",
    "    \n",
    "    dimension_ : int\n",
    "        Intrinsic dimension of the dataset\n",
    "\n",
    "    -----------\n",
    "    References:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, k = 20, D = 100):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : dummy parameter to respect the sklearn API\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        if len(X) == 1:\n",
    "            raise ValueError(\"Can't fit with 1 sample\")\n",
    "        if X.shape[1]==1:\n",
    "            raise ValueError(\"Can't fit with n_features = 1\")\n",
    "        if not np.isfinite(X).all():\n",
    "            raise ValueError(\"X contains inf or NaN\")\n",
    "        if self.k >= len(X):\n",
    "            warnings.warn('k >= len(X), using k = len(X)-1')\n",
    "        \n",
    "        \n",
    "        dists, inds = get_nn(X,min(self.k,len(X)-1))\n",
    "        \n",
    "        self.dimension_ = self._idmom(dists.T)\n",
    "                    \n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        return self  \n",
    "\n",
    "\n",
    "    def idmind_ml1(dists):\n",
    "        n = dists.shape[1]\n",
    "        dists2 = dists**2  # need only squared dists to first 2 neighbors\n",
    "        s = np.sum(np.log(dists2[0, :]/dists2[1, :]), axis=0)\n",
    "        ID = -2/(s/n)\n",
    "        return ID\n",
    "\n",
    "\n",
    "    def idmind_mli(dists, D):\n",
    "        k = len(dists)\n",
    "        n = dists.shape[1]\n",
    "        nlogk = n*np.log(k)\n",
    "        rho = dists[0, :]/dists[k-1, :]\n",
    "        ll = np.zeros(D)\n",
    "        sum1 = np.sum(np.log(rho))\n",
    "        for d in range(1, D+1):\n",
    "            sum2 = np.sum(np.log(1-rho**d))\n",
    "            ll[d-1] = nlogk + n*np.log(d) + (d-1)*sum1 + (k-1)*sum2\n",
    "        ID = np.argmax(ll)+1\n",
    "        return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import i0,i1,digamma,gammainc\n",
    "from scipy.interpolate import interp1d,interp2d\n",
    "from _commonfuncs import binom_coeff, get_nn, randsphere, lens, indnComb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists,inds = get_nn(data,k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, array([7.64707522]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIND_MLx(data,k=20,D=10,ver='MIND_MLi'),MIND_MLx(data,k=20,D=10,ver='MIND_MLk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7.352174886192938)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idmind_mli(dists.T,D=10),idmind_ml1(dists.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from _commonfuncs import get_nn\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_array, check_random_state\n",
    "\n",
    "\n",
    "class MiND_ML(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class to calculate the intrinsic dimension of the provided data points with the MiND_MLx algorithms.\n",
    "    \n",
    "    -----------\n",
    "    Attributes\n",
    "    \n",
    "    k : int, default=20\n",
    "        Neighborhood parameter for ver='MLk' or ver='MLi'. ver='ML1' uses the first two neighbor distances.\n",
    "    ver : str\n",
    "        'MLk' or 'MLi' or 'ML1'. See the reference paper\n",
    "    -----------\n",
    "    Returns\n",
    "    \n",
    "    dimension_ : int\n",
    "        Intrinsic dimension of the dataset\n",
    "\n",
    "    -----------\n",
    "    References\n",
    "    \n",
    "    Rozza, A., Lombardi, G., Ceruti, C., Casiraghi, E., & Campadelli, P. (2012). Novel high intrinsic dimensionality estimators. \n",
    "    Machine Learning, 89(1-2), 37–65. doi:10.1007/s10994-012-5294-7 \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, k = 20, D = 10, ver = 'MLk'):\n",
    "        self.k = k\n",
    "        self.D = D\n",
    "        self.ver = ver\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : dummy parameter to respect the sklearn API\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        if len(X) == 1:\n",
    "            raise ValueError(\"Can't fit with 1 sample\")\n",
    "        if X.shape[1]==1:\n",
    "            raise ValueError(\"Can't fit with n_features = 1\")\n",
    "        if not np.isfinite(X).all():\n",
    "            raise ValueError(\"X contains inf or NaN\")\n",
    "        if self.k+1 >= len(X):\n",
    "            warnings.warn('k+1 >= len(X), using k+1 = len(X)-1')\n",
    "                \n",
    "        self.dimension_ = self._MiND_MLx(X)\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        return self  \n",
    "\n",
    "    def _MiND_MLx(self, X):\n",
    "        nbh_data,idx = get_nn(X, min(self.k+1,len(X)-1))\n",
    "\n",
    "        if (self.ver == 'ML1'):\n",
    "            return self._MiND_ML1(nbh_data)\n",
    "\n",
    "        rhos = nbh_data[:,0]/nbh_data[:,-1]\n",
    "\n",
    "        d_MIND_MLi = self._MiND_MLi(rhos)\n",
    "        if (self.ver == 'MLi'):\n",
    "            return(d_MIND_MLi)\n",
    "\n",
    "        d_MIND_MLk = self._MiND_MLk(rhos, d_MIND_MLi)\n",
    "        if (self.ver == 'MLk'):\n",
    "            return(d_MIND_MLk)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown version: \", self.ver)\n",
    "                              \n",
    "    @staticmethod\n",
    "    def _MiND_ML1(nbh_data):\n",
    "        n = len(nbh_data)\n",
    "        dists2 = nbh_data[:,:2]**2  # need only squared dists to first 2 neighbors\n",
    "        s = np.sum(np.log(dists2[:,0]/dists2[:,1]))\n",
    "        ID = -2/(s/n)\n",
    "        return ID\n",
    "\n",
    "    def _MiND_MLi(self, rhos):\n",
    "        #MIND MLI MLK REVERSED COMPARED TO R TO CORRESPOND TO PAPER\n",
    "        N = len(rhos)\n",
    "        d_lik = np.array([np.nan]*self.D)\n",
    "        for d in range(self.D):\n",
    "            d_lik[d] = lld(d, rhos, self.k, N)\n",
    "        return(np.argmax(d_lik))\n",
    "\n",
    "    def _MiND_MLk(self, rhos, dinit):\n",
    "        #MIND MLI MLK REVERSED COMPARED TO R TO CORRESPOND TO PAPER\n",
    "        res = minimize(fun=nlld,\n",
    "                x0=np.array([dinit]),\n",
    "                jac=nlld_gr,\n",
    "                args=(rhos, self.k, len(rhos)),\n",
    "                method = 'L-BFGS-B',\n",
    "                bounds=[(0,self.D)])\n",
    "\n",
    "        return(res['x'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlld(d, rhos, k, N):\n",
    "    return(-lld(d, rhos, k, N))\n",
    "\n",
    "def lld(d, rhos, k, N):\n",
    "    if (d == 0):\n",
    "        return(np.array([-1e30]))\n",
    "    else:\n",
    "        return N*np.log(k*d) + (d-1)*np.sum(np.log(rhos)) + (k-1)*np.sum(np.log(1-rhos**d))\n",
    "    \n",
    "def nlld_gr(d, rhos, k, N):\n",
    "    if (d == 0):\n",
    "        return(np.array([-1e30]))\n",
    "    else:\n",
    "        return -(N/d + np.sum(np.log(rhos) - (k-1)*(rhos**d)*np.log(rhos)/(1 - rhos**d)))\n",
    "\n",
    "\n",
    "def MIND_MLi(rhos, k, D):\n",
    "    #MIND MLI MLK REVERSED COMPARED TO R TO CORRESPOND TO PAPER\n",
    "    N = len(rhos)\n",
    "    d_lik = np.array([np.nan]*D)\n",
    "    for d in range(D):\n",
    "        d_lik[d] = lld(d, rhos, k, N)\n",
    "    return(np.argmax(d_lik))\n",
    "\n",
    "def MIND_MLk(rhos, k, D, dinit):\n",
    "    #MIND MLI MLK REVERSED COMPARED TO R TO CORRESPOND TO PAPER\n",
    "    res = minimize(fun=nlld,\n",
    "            x0=np.array([dinit]),\n",
    "            jac=nlld_gr,\n",
    "            args=(rhos, k, len(rhos)),\n",
    "            method = 'L-BFGS-B',\n",
    "            bounds=[(0,D)])\n",
    "\n",
    "    #if(!is.null(res$message)) print(res$message)\n",
    "    return(res['x'])  \n",
    "\n",
    "def idmind_ml1(dists):\n",
    "    n = dists.shape[1]\n",
    "    dists2 = dists[:2]**2  # need only squared dists to first 2 neighbors\n",
    "    s = np.sum(np.log(dists2[0, :]/dists2[1, :]), axis=0)\n",
    "    ID = -2/(s/n)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def MIND_MLx(data, k, D, ver):\n",
    "    nbh_data,idx = get_nn(data, k+1)\n",
    "    \n",
    "    if (ver == 'ML1'):\n",
    "        \n",
    "    \n",
    "    rhos = nbh_data[:,0]/nbh_data[:,-1]\n",
    "    d_MIND_MLi = MIND_MLi(rhos, k, D)\n",
    "    if (ver == 'MLi'):\n",
    "        return(d_MIND_MLi)\n",
    "\n",
    "    d_MIND_MLk = MIND_MLk(rhos, k, D, d_MIND_MLi)\n",
    "    if (ver == 'MLk'):\n",
    "        return(d_MIND_MLk)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown version: \", ver)\n",
    "\n",
    "\n",
    "\n",
    "def idmind_ml1(dists):\n",
    "    n = dists.shape[1]\n",
    "    dists2 = dists[:2]**2  # need only squared dists to first 2 neighbors\n",
    "    s = np.sum(np.log(dists2[0, :]/dists2[1, :]), axis=0)\n",
    "    ID = -2/(s/n)\n",
    "    return ID\n",
    "\n",
    "def idmind_mli(dists, D):\n",
    "    k = len(dists)\n",
    "    n = dists.shape[1]\n",
    "    nlogk = n*np.log(k)\n",
    "    rho = dists[0, :]/dists[k-1, :]\n",
    "    ll = np.zeros(D)\n",
    "    sum1 = np.sum(np.log(rho))\n",
    "    for d in range(1, D+1):\n",
    "        sum2 = np.sum(np.log(1-rho**d))\n",
    "        ll[d-1] = nlogk + n*np.log(d) + (d-1)*sum1 + (k-1)*sum2\n",
    "    ID = np.argmax(ll)+1\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "def idmle(dists):\n",
    "    # dists - nearest-neighbor distances (k x 1, or k x n), sorted\n",
    "    # equivalent to R intdim.maxLikPointwiseDimEst with no kwargs\n",
    "    k = len(dists)\n",
    "    xi = np.sum(np.log(dists / dists[[k-1], :]), axis=0) / (k-1)\n",
    "    ID = -(1 / xi)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmom(dists):\n",
    "    # dists - nearest-neighbor distances (k x 1, or k x n), sorted\n",
    "    k = len(dists)\n",
    "    w = dists[k-1, :]\n",
    "    m1 = np.sum(dists, axis=0)/k\n",
    "    ID = -m1 / (m1-w)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idpca(X, theta):\n",
    "    # X - data set (n x d)\n",
    "    # theta - ratio of variance to preserve (theta \\in [0,1])\n",
    "    pca = PCA().fit(X)\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    d = X.shape[1]\n",
    "    theta = theta*100\n",
    "    ID = 1\n",
    "    sumexp = explained[ID-1]\n",
    "    while ID < d and sumexp < theta:\n",
    "        ID += 1\n",
    "    sumexp = sumexp + explained[ID-1]\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmind_ml1(dists):\n",
    "    n = dists.shape[1]\n",
    "    dists2 = dists**2  # need only squared dists to first 2 neighbors\n",
    "    s = np.sum(np.log(dists2[0, :]/dists2[1, :]), axis=0)\n",
    "    ID = -2/(s/n)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmind_mli(dists, D):\n",
    "    k = len(dists)\n",
    "    n = dists.shape[1]\n",
    "    nlogk = n*np.log(k)\n",
    "    rho = dists[0, :]/dists[k-1, :]\n",
    "    ll = np.zeros(D)\n",
    "    sum1 = np.sum(np.log(rho))\n",
    "    for d in range(1, D+1):\n",
    "        sum2 = np.sum(np.log(1-rho**d))\n",
    "        ll[d-1] = nlogk + n*np.log(d) + (d-1)*sum1 + (k-1)*sum2\n",
    "    ID = np.argmax(ll)+1\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idtle(X, dists, epsilon=0.0001):\n",
    "\n",
    "    # X - matrix of nearest neighbors (k x d), sorted by distance\n",
    "    # dists - nearest-neighbor distances (k x 1), sorted\n",
    "    r = dists[0, -1]  # distance to k-th neighbor\n",
    "\n",
    "    # Boundary case 1: If $r = 0$, this is fatal, since the neighborhood would be degenerate.\n",
    "    if r == 0:\n",
    "        raise ValueError('All k-NN distances are zero!')\n",
    "    # Main computation\n",
    "    k = dists.shape[1]\n",
    "    V = squareform(pdist(X))\n",
    "    Di = np.tile(dists.T, (1, k))\n",
    "    Dj = Di.T\n",
    "    Z2 = 2*Di**2 + 2*Dj**2 - V**2\n",
    "    S = r * (((Di**2 + V**2 - Dj**2)**2 + 4*V**2 * (r**2 - Di**2))\n",
    "             ** 0.5 - (Di**2 + V**2 - Dj**2)) / (2*(r**2 - Di**2))\n",
    "    T = r * (((Di**2 + Z2 - Dj**2)**2 + 4*Z2 * (r**2 - Di**2))\n",
    "             ** 0.5 - (Di**2 + Z2 - Dj**2)) / (2*(r**2 - Di**2))\n",
    "    Dr = (dists == r).squeeze()  # handle case of repeating k-NN distances\n",
    "    S[Dr, :] = r * V[Dr, :]**2 / (r**2 + V[Dr, :]**2 - Dj[Dr, :]**2)\n",
    "    T[Dr, :] = r * Z2[Dr, :] / (r**2 + Z2[Dr, :] - Dj[Dr, :]**2)\n",
    "    # Boundary case 2: If $u_i = 0$, then for all $1\\leq j\\leq k$ the measurements $s_{ij}$ and $t_{ij}$ reduce to $u_j$.\n",
    "    Di0 = (Di == 0).squeeze()\n",
    "    T[Di0] = Dj[Di0]\n",
    "    S[Di0] = Dj[Di0]\n",
    "    # Boundary case 3: If $u_j = 0$, then for all $1\\leq j\\leq k$ the measurements $s_{ij}$ and $t_{ij}$ reduce to $\\frac{r v_{ij}}{r + v_{ij}}$.\n",
    "    Dj0 = (Dj == 0).squeeze()\n",
    "    T[Dj0] = r * V[Dj0] / (r + V[Dj0])\n",
    "    S[Dj0] = r * V[Dj0] / (r + V[Dj0])\n",
    "    # Boundary case 4: If $v_{ij} = 0$, then the measurement $s_{ij}$ is zero and must be dropped. The measurement $t_{ij}$ should be dropped as well.\n",
    "    V0 = (V == 0).squeeze()\n",
    "    np.fill_diagonal(V0, False)\n",
    "    T[V0] = r  # by setting to r, $t_{ij}$ will not contribute to the sum s1t\n",
    "    S[V0] = r  # by setting to r, $s_{ij}$ will not contribute to the sum s1s\n",
    "    # will subtract twice this number during ID computation below\n",
    "    nV0 = np.sum(V0)\n",
    "    # Drop T & S measurements below epsilon (V4: If $s_{ij}$ is thrown out, then for the sake of balance, $t_{ij}$ should be thrown out as well (or vice versa).)\n",
    "    TSeps = (T < epsilon) | (S < epsilon)\n",
    "    np.fill_diagonal(TSeps, 0)\n",
    "    nTSeps = np.sum(TSeps)\n",
    "    T[TSeps] = r\n",
    "    T = np.log(T/r)\n",
    "    S[TSeps] = r\n",
    "    S = np.log(S/r)\n",
    "    np.fill_diagonal(T, 0)  # delete diagonal elements\n",
    "    np.fill_diagonal(S, 0)\n",
    "    # Sum over the whole matrices\n",
    "    s1t = np.sum(T)\n",
    "    s1s = np.sum(S)\n",
    "    # Drop distances below epsilon and compute sum\n",
    "    Deps = dists < epsilon\n",
    "    nDeps = np.sum(Deps, dtype=int)\n",
    "    dists = dists[nDeps:]\n",
    "    s2 = np.sum(np.log(dists/r))\n",
    "    # Compute ID, subtracting numbers of dropped measurements\n",
    "    ID = -2*(k**2-nTSeps-nDeps-nV0) / (s1t+s1s+2*s2)\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
