{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skdim import global_id\n",
    "from skdim import local_id\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "utils = rpackages.importr('utils')\n",
    "#utils.install_packages('intrinsicDimension')\n",
    "#utils.install_packages('ider')\n",
    "intdimr = rpackages.importr('intrinsicDimension')\n",
    "ider   = rpackages.importr('ider')\n",
    "r_base = rpackages.importr('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.random((500,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corint = global_id.CorrInt().fit(data)\n",
    "danco = global_id.DANCo().fit(data)\n",
    "knn = global_id.KNN().fit(data)\n",
    "mada = global_id.Mada().fit(data)\n",
    "twonn = global_id.TwoNN().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = local_id.ESS().fit(data)\n",
    "fishers = local_id.FisherS().fit(data)\n",
    "lpca = local_id.lPCA().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>FloatVector with 1 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            2.896146\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "R object with classes: ('numeric',) mapped to:\n",
       "[2.896146]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intdimr.maxLikLocalDimEst(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.896146155422213"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLikLocalDimEst(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension estimate: 6.312511 \n"
     ]
    }
   ],
   "source": [
    "%%R -i data\n",
    "r=maxLikGlobalDimEst(data,k=10)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.312510995146283"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data 2D array-like\n",
    "a data set for which the intrinsic dimension is estimated.\n",
    "k \t\n",
    "\n",
    "neighborhood parameter.\n",
    "D \t\n",
    "\n",
    "maximal dimension.\n",
    "ver \t\n",
    "possible values: 'DANCo', 'MIND_MLi', 'MIND_MLk'.\n",
    "calibration_data : dict\n",
    "    Precomputed calibration data returned after fitting DANCo a first time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import scipy.integrate\n",
    "import numpy as np\n",
    "from _commonfuncs import lens, get_nn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "\n",
    "class MLE(BaseEstimator):    \n",
    "    \"\"\"Maximum likelihood estimator of intrinsic dimension.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo_param'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    \"\"\"\n",
    "    def __init__(self, k, dnoise = None, sigma = 0, n = None,\n",
    "                    integral_approximation = 'Haro', unbiased = False,\n",
    "                    neighborhood_based = True,\n",
    "                    neighborhood_aggregation = 'maximum.likelihood',\n",
    "                    iterations = 5, K = 5):\n",
    "        \n",
    "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
    "        values.pop(\"self\")\n",
    "\n",
    "        for arg, val in values.items():\n",
    "            setattr(self, arg, val)\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        self.dimension_, self.kl_divergence_, self.calibration_data_ = self._dancoDimEst(X)\n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        return self    \n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    def maxLikGlobalDimEst(data, k, dnoise = None, sigma = 0, n = None,\n",
    "                        integral_approximation = 'Haro', unbiased = False,\n",
    "                        neighborhood_based = True,\n",
    "                        neighborhood_aggregation = 'maximum.likelihood',\n",
    "                        iterations = 5, K = 5):\n",
    "      # 'k' is the number of neighbors used for each dimension estimation.\n",
    "      # 'dnoise' is a vector valued function giving the transition density.\n",
    "      # 'sigma' is the estimated standard deviation for the noise.\n",
    "      # 'n' is the dimension of the noise (at least dim(data)[2])\n",
    "      # integral.approximation can take values 'Haro', 'guaranteed.convergence', 'iteration'\n",
    "      # neighborhood.based means that estimation is made for each neighborhood,\n",
    "      # otherwise estimation is based on distances in entire data set.\n",
    "      # 'K' is number of neighbors per data point that is considered, only used for \n",
    "      # neighborhood.based = False\n",
    "\n",
    "        N = len(data)\n",
    "\n",
    "        if (neighborhood_based):\n",
    "            mi = maxLikPointwiseDimEst(data, k, dnoise, sigma, n,\n",
    "                               integral_approximation = integral_approximation,\n",
    "                               unbiased = unbiased)\n",
    "\n",
    "            if neighborhood_aggregation == 'maximum.likelihood':\n",
    "                de = 1/np.mean(1/mi) \n",
    "\n",
    "            elif neighborhood_aggregation == 'mean':\n",
    "                de = np.mean(mi) \n",
    "            elif neighborhood_aggregation == 'median':\n",
    "                de = robust = np.median(mi)\n",
    "            return(de)\n",
    "\n",
    "\n",
    "        dist, idx = get_nn(data, K)\n",
    "        #dist = dist[~duplicated(dist[range(K*N)])]\n",
    "        Rs = dist\n",
    "        de = maxLikDimEstFromR(Rs, dnoise, np.sqrt(2)*sigma, n, integral_approximation, unbiased,\n",
    "                iterations) # Since distances between points are used, noise is \n",
    "                            # added at both ends, i.e. variance is doubled. \n",
    "\n",
    "                  #likelihood = np.nan\n",
    "        return(de, np.nan) \n",
    "\n",
    "\n",
    "    def maxLikPointwiseDimEst(data, k, dnoise = None, sigma = 0, n = None, indices = None,\n",
    "                             integral_approximation = 'Haro', unbiased = False,\n",
    "                             iterations = 5):\n",
    "        ## estimates dimension around each point in data[indices, ]\n",
    "        #\n",
    "        # 'indices' give the indexes for which local dimension estimation should\n",
    "        # be performed.\n",
    "        # 'k' is the number of neighbors used for each local dimension estimation.\n",
    "        # 'dnoise' is a vector valued function giving the transition density.\n",
    "        # 'sigma' is the estimated standard deviation for the noise.\n",
    "        # 'n' is the dimension of the noise (at least dim(data)[2])\n",
    "\n",
    "        if indices is None:\n",
    "            indices = np.arange(len(data))\n",
    "\n",
    "        N = len(indices)\n",
    "        nbh_dist, idx = get_nn(data, k)\n",
    "        de = np.repeat(np.nan, N) # This vector will hold local dimension estimates\n",
    "\n",
    "        for i in range(N):\n",
    "            Rs = nbh_dist[i,:]\n",
    "            de[i] = maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation, unbiased, iterations)\n",
    "\n",
    "        return(de)\n",
    "\n",
    "\n",
    "    def maxLikLocalDimEst(data, dnoise = None, sigma = 0, n = None,\n",
    "                       integral_approximation = 'Haro',\n",
    "                       unbiased = False, iterations = 5):\n",
    "\n",
    "        # assuming data set is local\n",
    "        center = np.mean(data, axis=0)\n",
    "        cent_data = data - center\n",
    "        Rs = np.sort(lens(cent_data))\n",
    "        de = maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation, unbiased, iterations)\n",
    "        return(de)\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    def maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation = 'Haro',\n",
    "                    unbiased = False, iterations = 5):\n",
    "\n",
    "        if integral_approximation not in ['Haro', 'guaranteed.convergence', 'iteration']:\n",
    "            raise ValueError('Wrong integral approximation')\n",
    "\n",
    "        if not type(dnoise) == 'closure' and dnoise is not None: \n",
    "            if not callable(dnoise):\n",
    "                raise ValueError('dnoise must be a function')\n",
    "            dnoise_orig = dnoise\n",
    "        if not integral_approximation == 'Haro' and dnoise is not None:\n",
    "            dnoise = lambda r, s, sigma, k: r*dnoise_orig(r, s, sigma, k)\n",
    "\n",
    "        de = maxLikDimEstFromR_haro_approx(Rs, dnoise, sigma, n, unbiased)\n",
    "        if (integral_approximation == 'iteration'):\n",
    "            de = maxLikDimEstFromRIterative(Rs, dnoise_orig, sigma, n, de, unbiased)\n",
    "\n",
    "        return(de)\n",
    "    ################################################################################\n",
    "\n",
    "    def maxLikDimEstFromR_haro_approx(Rs, dnoise, sigma, n, unbiased = False):\n",
    "        # if dnoise is the noise function this is the approximation used in Haro.\n",
    "        # for 'guaranteed.convergence' dnoise should be r times the noise function\n",
    "        # with 'unbiased' option, estimator is unbiased if no noise or boundary\n",
    "\n",
    "        k = len(Rs)\n",
    "        kfac = k-2 if unbiased else k-1\n",
    "\n",
    "        Rk = max(Rs)\n",
    "        if dnoise is None:\n",
    "            return(kfac/(sum(np.log(Rk/Rs))))\n",
    "\n",
    "        Rpr = Rk + 100*sigma\n",
    "\n",
    "        numerator = np.repeat(np.nan, k - 1)\n",
    "        denominator = np.repeat(np.nan, k - 1)\n",
    "\n",
    "        for j in range(k-1):\n",
    "            Rj = Rs[j]\n",
    "\n",
    "            try:\n",
    "                tc = scipy.integrate.quad(lambda x: dnoise(x, Rj, sigma, n) * np.log(Rk/x), 0, Rpr, epsrel = 1e-2)\n",
    "            except:\n",
    "                tc = np.nan\n",
    "\n",
    "            if np.isnan(tc)[0]:\n",
    "                return(np.nan)\n",
    "\n",
    "            numerator[j] = numInt['value']\n",
    "\n",
    "            try:\n",
    "                tc = scipy.integrate.quad(lambda x: dnoise(x, Rj, sigma, n), 0, Rpr, epsrel = 1e-2)\n",
    "            except:\n",
    "                tc = np.nan\n",
    "\n",
    "            if np.isnan(tc)[0]:\n",
    "                return(np.nan)\n",
    "\n",
    "            denominator[j] = denomInt['value']\n",
    "\n",
    "        return(kfac/sum(numerator/denominator))\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    def maxLikDimEstFromRIterative(Rs, dnoise, sigma, n, init = 5,\n",
    "                      unbiased = False, iterations = 5, verbose = False):\n",
    "        m = init\n",
    "        if verbose:\n",
    "            print(\"Start iteration, intial value:\", m, \"\\n\")\n",
    "        for i in range(iterations):\n",
    "            m = maxLikDimEstFromRIterative_inner(Rs, dnoise, sigma, n, m, unbiased)\n",
    "            if verbose:\n",
    "                print(\"Iteration\", i, \":\", m, \"\\n\")\n",
    "            if verbose:\n",
    "                print(\"\\n\")\n",
    "        return(m)\n",
    "\n",
    "    def maxLikDimEstFromRIterative_inner(Rs, dnoise, sigma, n, m, unbiased):\n",
    "\n",
    "        k = len(Rs)  \n",
    "        kfac = k-2 if unbiased else k-1\n",
    "\n",
    "        Rk = max(Rs)\n",
    "        if dnoise is None:\n",
    "            return(kfac/(sum(np.log(Rk/Rs))))\n",
    "        Rpr = Rk + 100*sigma\n",
    "\n",
    "        numerator = np.repeat(np.nan, k - 1)\n",
    "        denominator = np.repeat(np.nan, k - 1)\n",
    "\n",
    "        for j in range(k-1):\n",
    "            Rj = Rs[j]\n",
    "            m = max(m, 1)\n",
    "            numInt = scipy.integrate.quad(lambda x: x**(m-1)*dnoise(x, Rj, sigma, n) * np.log(Rk/x), 0, Rpr, epsrel = 1e-2)\n",
    "            numerator[j] = numInt['value']\n",
    "\n",
    "            denomInt = scipy.integrate.quad(lambda x: x**(m-1)*dnoise(x, Rj, sigma, n), 0, Rpr, epsrel = 1e-2)\n",
    "            denominator[j] = denomInt['value']\n",
    "\n",
    "        return(kfac/sum(numerator/denominator))\n",
    "\n",
    "\n",
    "\n",
    "    def dnoiseGaussH(r, s, sigma, k = None):\n",
    "        if (len(r) > 1 and len(s) > 1):\n",
    "            raise ValueError('r and s cannot both be vectors')\n",
    "        dnorm(s, r, sigma)              # f(s|r) in Haro et al. (2008) w/ Gaussian\n",
    "                                            # transition density\n",
    "                                            # 'k' is not used, but is input\n",
    "                                            # for compatibility\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    def dnoiseGaussB(r, s, sigma, k):\n",
    "\n",
    "        if (len(r) > 1 and len(s) > 1):\n",
    "            raise ValueError('r and s cannot both be vectors')\n",
    "        w1 = inthr(s, k, sigma)\n",
    "        mu = intrhr(s, k, sigma)/w1\n",
    "        tsigma2 = intr2hr(s, k, sigma)/w1 - mu^2\n",
    "        w2 = 1 - pnorm(0, mean = mu, sd = sqrt(tsigma2))\n",
    "        w = w1/w2\n",
    "        gau = w*dnorm(r, mu, sqrt(tsigma2))\n",
    "        return(gau*(r > 0))   # Best approximation of f(s|r) by truncated Gaussian\n",
    "                            # when Gaussian k-dim noise.\n",
    "                            # NB! The noncentral chi distribution is\n",
    "                            # f(r|s), not f(s|r).\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    def dnoiseNcChi(r, s, sigma, k):\n",
    "\n",
    "        if len(r) > 1 and len(s) > 1:\n",
    "            raise ValueError('r and s cannot both be vectors')\n",
    "        _lambda = r/sigma\n",
    "        return 2*s/sigma**2*dchisq((s/sigma)**2, k, _lambda**2) # 'k' is the number of\n",
    "                                                     # degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate\n",
    "import numpy as np\n",
    "from _commonfuncs import lens, get_nn\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def maxLikGlobalDimEst(data, k, dnoise = None, sigma = 0, n = None,\n",
    "                    integral_approximation = 'Haro', unbiased = False,\n",
    "                    neighborhood_based = True,\n",
    "                    neighborhood_aggregation = 'maximum.likelihood',\n",
    "                    iterations = 5, K = 5):\n",
    "  # 'k' is the number of neighbors used for each dimension estimation.\n",
    "  # 'dnoise' is a vector valued function giving the transition density.\n",
    "  # 'sigma' is the estimated standard deviation for the noise.\n",
    "  # 'n' is the dimension of the noise (at least dim(data)[2])\n",
    "  # integral.approximation can take values 'Haro', 'guaranteed.convergence', 'iteration'\n",
    "  # neighborhood.based means that estimation is made for each neighborhood,\n",
    "  # otherwise estimation is based on distances in entire data set.\n",
    "  # 'K' is number of neighbors per data point that is considered, only used for \n",
    "  # neighborhood.based = False\n",
    "\n",
    "    N = len(data)\n",
    "\n",
    "    if (neighborhood_based):\n",
    "        mi = maxLikPointwiseDimEst(data, k, dnoise, sigma, n,\n",
    "                           integral_approximation = integral_approximation,\n",
    "                           unbiased = unbiased)\n",
    "        \n",
    "        if neighborhood_aggregation == 'maximum.likelihood':\n",
    "            de = 1/np.mean(1/mi) \n",
    "            \n",
    "        elif neighborhood_aggregation == 'mean':\n",
    "            de = np.mean(mi) \n",
    "        elif neighborhood_aggregation == 'median':\n",
    "            de = robust = np.median(mi)\n",
    "        return(de)\n",
    "\n",
    "\n",
    "    dist, idx = get_nn(data, K)\n",
    "    #dist = dist[~duplicated(dist[range(K*N)])]\n",
    "    Rs = dist\n",
    "    de = maxLikDimEstFromR(Rs, dnoise, np.sqrt(2)*sigma, n, integral_approximation, unbiased,\n",
    "            iterations) # Since distances between points are used, noise is \n",
    "                        # added at both ends, i.e. variance is doubled. \n",
    "        \n",
    "              #likelihood = np.nan\n",
    "    return(de, np.nan) \n",
    "\n",
    "\n",
    "def maxLikPointwiseDimEst(data, k, dnoise = None, sigma = 0, n = None, indices = None,\n",
    "                         integral_approximation = 'Haro', unbiased = False,\n",
    "                         iterations = 5):\n",
    "    ## estimates dimension around each point in data[indices, ]\n",
    "    #\n",
    "    # 'indices' give the indexes for which local dimension estimation should\n",
    "    # be performed.\n",
    "    # 'k' is the number of neighbors used for each local dimension estimation.\n",
    "    # 'dnoise' is a vector valued function giving the transition density.\n",
    "    # 'sigma' is the estimated standard deviation for the noise.\n",
    "    # 'n' is the dimension of the noise (at least dim(data)[2])\n",
    "\n",
    "    if indices is None:\n",
    "        indices = np.arange(len(data))\n",
    "\n",
    "    N = len(indices)\n",
    "    nbh_dist, idx = get_nn(data, k)\n",
    "    de = np.repeat(np.nan, N) # This vector will hold local dimension estimates\n",
    "\n",
    "    for i in range(N):\n",
    "        Rs = nbh_dist[i,:]\n",
    "        de[i] = maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation, unbiased, iterations)\n",
    "\n",
    "    return(de)\n",
    "\n",
    "\n",
    "def maxLikLocalDimEst(data, dnoise = None, sigma = 0, n = None,\n",
    "                   integral_approximation = 'Haro',\n",
    "                   unbiased = False, iterations = 5):\n",
    "    \n",
    "    # assuming data set is local\n",
    "    center = np.mean(data, axis=0)\n",
    "    cent_data = data - center\n",
    "    Rs = np.sort(lens(cent_data))\n",
    "    de = maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation, unbiased, iterations)\n",
    "    return(de)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def maxLikDimEstFromR(Rs, dnoise, sigma, n, integral_approximation = 'Haro',\n",
    "                unbiased = False, iterations = 5):\n",
    "\n",
    "    if integral_approximation not in ['Haro', 'guaranteed.convergence', 'iteration']:\n",
    "        raise ValueError('Wrong integral approximation')\n",
    "\n",
    "    if not type(dnoise) == 'closure' and dnoise is not None: \n",
    "        if not callable(dnoise):\n",
    "            raise ValueError('dnoise must be a function')\n",
    "        dnoise_orig = dnoise\n",
    "    if not integral_approximation == 'Haro' and dnoise is not None:\n",
    "        dnoise = lambda r, s, sigma, k: r*dnoise_orig(r, s, sigma, k)\n",
    "\n",
    "    de = maxLikDimEstFromR_haro_approx(Rs, dnoise, sigma, n, unbiased)\n",
    "    if (integral_approximation == 'iteration'):\n",
    "        de = maxLikDimEstFromRIterative(Rs, dnoise_orig, sigma, n, de, unbiased)\n",
    "\n",
    "    return(de)\n",
    "################################################################################\n",
    "\n",
    "def maxLikDimEstFromR_haro_approx(Rs, dnoise, sigma, n, unbiased = False):\n",
    "    # if dnoise is the noise function this is the approximation used in Haro.\n",
    "    # for 'guaranteed.convergence' dnoise should be r times the noise function\n",
    "    # with 'unbiased' option, estimator is unbiased if no noise or boundary\n",
    "\n",
    "    k = len(Rs)\n",
    "    kfac = k-2 if unbiased else k-1\n",
    "\n",
    "    Rk = max(Rs)\n",
    "    if dnoise is None:\n",
    "        return(kfac/(sum(np.log(Rk/Rs))))\n",
    "\n",
    "    Rpr = Rk + 100*sigma\n",
    "\n",
    "    numerator = np.repeat(np.nan, k - 1)\n",
    "    denominator = np.repeat(np.nan, k - 1)\n",
    "\n",
    "    for j in range(k-1):\n",
    "        Rj = Rs[j]\n",
    "        \n",
    "        try:\n",
    "            tc = scipy.integrate.quad(lambda x: dnoise(x, Rj, sigma, n) * np.log(Rk/x), 0, Rpr, epsrel = 1e-2)\n",
    "        except:\n",
    "            tc = np.nan\n",
    "\n",
    "        if np.isnan(tc)[0]:\n",
    "            return(np.nan)\n",
    "\n",
    "        numerator[j] = numInt['value']\n",
    "\n",
    "        try:\n",
    "            tc = scipy.integrate.quad(lambda x: dnoise(x, Rj, sigma, n), 0, Rpr, epsrel = 1e-2)\n",
    "        except:\n",
    "            tc = np.nan\n",
    "\n",
    "        if np.isnan(tc)[0]:\n",
    "            return(np.nan)\n",
    "        \n",
    "        denominator[j] = denomInt['value']\n",
    "\n",
    "    return(kfac/sum(numerator/denominator))\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def maxLikDimEstFromRIterative(Rs, dnoise, sigma, n, init = 5,\n",
    "                  unbiased = False, iterations = 5, verbose = False):\n",
    "    m = init\n",
    "    if verbose:\n",
    "        print(\"Start iteration, intial value:\", m, \"\\n\")\n",
    "    for i in range(iterations):\n",
    "        m = maxLikDimEstFromRIterative_inner(Rs, dnoise, sigma, n, m, unbiased)\n",
    "        if verbose:\n",
    "            print(\"Iteration\", i, \":\", m, \"\\n\")\n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "    return(m)\n",
    "\n",
    "def maxLikDimEstFromRIterative_inner(Rs, dnoise, sigma, n, m, unbiased):\n",
    "\n",
    "    k = len(Rs)  \n",
    "    kfac = k-2 if unbiased else k-1\n",
    "\n",
    "    Rk = max(Rs)\n",
    "    if dnoise is None:\n",
    "        return(kfac/(sum(log(Rk/Rs))))\n",
    "    Rpr = Rk + 100*sigma\n",
    "\n",
    "    numerator = np.repeat(np.nan, k - 1)\n",
    "    denominator = np.repeat(np.nan, k - 1)\n",
    "\n",
    "    for j in range(k-1):\n",
    "        Rj = Rs[j]\n",
    "        m = max(m, 1)\n",
    "        numInt = scipy.integrate.quad(lambda x: x**(m-1)*dnoise(x, Rj, sigma, n) * np.log(Rk/x), 0, Rpr, epsrel = 1e-2)\n",
    "        numerator[j] = numInt['value']\n",
    "\n",
    "        denomInt = scipy.integrate.quad(lambda x: x**(m-1)*dnoise(x, Rj, sigma, n), 0, Rpr, epsrel = 1e-2)\n",
    "        denominator[j] = denomInt['value']\n",
    "\n",
    "    return(kfac/sum(numerator/denominator))\n",
    "\n",
    "\n",
    "\n",
    "def dnoiseGaussH(r, s, sigma, k = None):\n",
    "    if (len(r) > 1 and len(s) > 1):\n",
    "        raise ValueError('r and s cannot both be vectors')\n",
    "    dnorm(s, r, sigma)              # f(s|r) in Haro et al. (2008) w/ Gaussian\n",
    "                                        # transition density\n",
    "                                        # 'k' is not used, but is input\n",
    "                                        # for compatibility\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def dnoiseGaussB(r, s, sigma, k):\n",
    "\n",
    "    if (len(r) > 1 and len(s) > 1):\n",
    "        raise ValueError('r and s cannot both be vectors')\n",
    "    w1 = inthr(s, k, sigma)\n",
    "    mu = intrhr(s, k, sigma)/w1\n",
    "    tsigma2 = intr2hr(s, k, sigma)/w1 - mu^2\n",
    "    w2 = 1 - pnorm(0, mean = mu, sd = sqrt(tsigma2))\n",
    "    w = w1/w2\n",
    "    gau = w*dnorm(r, mu, sqrt(tsigma2))\n",
    "    return(gau*(r > 0))   # Best approximation of f(s|r) by truncated Gaussian\n",
    "                        # when Gaussian k-dim noise.\n",
    "                        # NB! The noncentral chi distribution is\n",
    "                        # f(r|s), not f(s|r).\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def dnoiseNcChi(r, s, sigma, k):\n",
    "\n",
    "    if len(r) > 1 and len(s) > 1:\n",
    "        raise ValueError('r and s cannot both be vectors')\n",
    "    _lambda = r/sigma\n",
    "    return 2*s/sigma**2*dchisq((s/sigma)**2, k, _lambda**2) # 'k' is the number of\n",
    "                                                 # degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
