{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdim import global_id\n",
    "from skdim import local_id\n",
    "from _commonfuncs import get_nn\n",
    "import sklearn.utils.estimator_checks as sktest\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "utils = rpackages.importr('utils')\n",
    "#utils.install_packages('intrinsicDimension')\n",
    "#utils.install_packages('ider')\n",
    "intdimr = rpackages.importr('intrinsicDimension')\n",
    "ider   = rpackages.importr('ider')\n",
    "r_base = rpackages.importr('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.random((200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Computing DANCo calibration data for N = 500, k = 10 for dimensions 1 to 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = intdimr.pcaLocalDimEst(data,ver='FO')\n",
    "r_pca = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.dancoDimEst(data,k=10,D=10)\n",
    "r_danco = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.knnDimEst(data,k=10,ps=np.arange(11,50),M=5,gamma=2)\n",
    "r_knn = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikGlobalDimEst(data,k=20)\n",
    "r_gmle = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikLocalDimEst(data)\n",
    "r_lmle = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "res = intdimr.maxLikPointwiseDimEst(data,k=20)\n",
    "r_pmle = np.array([i[0] for i in res])\n",
    "\n",
    "res = intdimr.pcaOtpmPointwiseDimEst(data,N=50)\n",
    "r_pcaOtpm = [np.array([i[0] for i in res]), np.array([i[1] for i in res])]\n",
    "\n",
    "\n",
    "r_corint = np.array(ider.corint(data,k1=10,k2=20))\n",
    "r_mada = np.array(ider.mada(data,local=True,k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corint = global_id.CorrInt().fit(data)\n",
    "danco = global_id.DANCo(D=10).fit(data)\n",
    "knn = global_id.KNN().fit(data)\n",
    "mada = global_id.Mada(local=True,k=20).fit(data)\n",
    "twonn = global_id.TwoNN().fit(data)\n",
    "\n",
    "ess = local_id.ESS().fit(data)\n",
    "fishers = local_id.FisherS().fit(data)\n",
    "lpca = local_id.lPCA().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lPCA_params(data):\n",
    "    try:\n",
    "        x = local_id.lPCA().fit(data)\n",
    "        x = local_id.lPCA(ver='fan').fit(data)\n",
    "        x = local_id.lPCA(ver='ratio').fit(data)\n",
    "        x = local_id.lPCA(ver='maxgap').fit(data)\n",
    "        x = local_id.lPCA(ver='').fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getmembers, isfunction, isclass\n",
    "from sklearn.utils.estimator_checks import parametrize_with_checks\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.testing import (assert_equal,\n",
    "                                   assert_array_equal,\n",
    "                                   assert_array_almost_equal,\n",
    "                                   assert_raises,\n",
    "                                   assert_in,\n",
    "                                   assert_not_in,\n",
    "                                   assert_no_warnings)\n",
    "\n",
    "def test_ess(data):\n",
    "    res = intdimr.essLocalDimEst(data)\n",
    "    r_ess = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "    assert (r_ess['dim.est'] == ess.dimension_ and r_ess['ess'] == ess.essval_)\n",
    "\n",
    "def test_corint(data): \n",
    "    corint = global_id.CorrInt(k1=10,k2=20).fit(data)\n",
    "    r_corint = np.array(ider.corint(data,k1=10,k2=20))\n",
    "    assert_equal(r_corint, corint.dimension_)\n",
    "        \n",
    "def test_mada(data): \n",
    "    r_mada = np.array(ider.mada(data,local=True,k=20))\n",
    "    mada = global_id.Mada(local=True,k=20).fit(data)\n",
    "    assert_array_almost_equal(r_mada,mada.dimension_)\n",
    "\n",
    "def test_fisher_params(data):\n",
    "    try:\n",
    "        x = local_id.FisherS().fit(data)\n",
    "        x = local_id.FisherS(ConditionalNumber=2).fit(data)\n",
    "        x = local_id.FisherS(ProducePlots=True).fit(data)\n",
    "        x = local_id.FisherS(ProjectOnSphere=False).fit(data)\n",
    "        x = local_id.FisherS(ncomp=True).fit(data)\n",
    "        x = local_id.FisherS(limit_maxdim=True).fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')\n",
    "\n",
    "def test_ess_params(data):\n",
    "    try:\n",
    "        x = local_id.ESS().fit(data)\n",
    "        x = local_id.ESS(ver='b').fit(data)\n",
    "        x = local_id.ESS(d=2).fit(data)\n",
    "    except:\n",
    "        raise AssertionError('test failed')\n",
    "\n",
    "def test_sklearn_compatible_estimator():\n",
    "    local_class_list = [o[1] for o in getmembers(local_id) if isclass(o[1])]\n",
    "    global_class_list = [o[1] for o in getmembers(global_id) if isclass(o[1])]\n",
    "    estimators = local_class_list+global_class_list\n",
    "\n",
    "    for estimator in estimators:\n",
    "        print(estimator)\n",
    "        check_estimator(estimator)\n",
    "\n",
    "res = intdimr.knnDimEst(data,k=10,ps=np.arange(11,50),M=1,gamma=2)\n",
    "r_knn = dict(zip(res.names,[np.array(i) for i in res]))\n",
    "\n",
    "knn = global_id.KNN(k=10,ps=np.arange(11,50),M=1,gamma=2).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'global_id._TwoNN.TwoNN'>\n",
      "<class 'global_id._Mada.Mada'>\n",
      "<class 'global_id._MLE.MLE'>\n",
      "<class 'global_id._KNN.KNN'>\n",
      "<class 'global_id._DANCo.DANCo'>\n",
      "<class 'global_id._CorrInt.CorrInt'>\n",
      "<class 'local_id._PCA.lPCA'>\n",
      "<class 'local_id._FisherS.FisherS'>\n",
      "<class 'local_id._ESS.ESS'>\n"
     ]
    }
   ],
   "source": [
    "test_sklearn_compatible_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists,inds = get_nn(data,k=100,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 405 ms, sys: 0 ns, total: 405 ms\n",
      "Wall time: 406 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for i in range(len(data)):\n",
    "    idtle(data[inds[i,:]],dists[[i],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "def idmle(dists):\n",
    "    # dists - nearest-neighbor distances (k x 1, or k x n), sorted\n",
    "    # equivalent to R intdim.maxLikPointwiseDimEst with no kwargs\n",
    "    k = len(dists)\n",
    "    xi = np.sum(np.log(dists / dists[[k-1], :]), axis=0) / (k-1)\n",
    "    ID = -(1 / xi)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmom(dists):\n",
    "    # dists - nearest-neighbor distances (k x 1, or k x n), sorted\n",
    "    k = len(dists)\n",
    "    w = dists[k-1, :]\n",
    "    m1 = np.sum(dists, axis=0)/k\n",
    "    ID = -m1 / (m1-w)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idpca(X, theta):\n",
    "    # X - data set (n x d)\n",
    "    # theta - ratio of variance to preserve (theta \\in [0,1])\n",
    "    pca = PCA().fit(X)\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    d = X.shape[1]\n",
    "    theta = theta*100\n",
    "    ID = 1\n",
    "    sumexp = explained[ID-1]\n",
    "    while ID < d and sumexp < theta:\n",
    "        ID += 1\n",
    "    sumexp = sumexp + explained[ID-1]\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmind_ml1(dists):\n",
    "    n = dists.shape[1]\n",
    "    dists2 = dists**2  # need only squared dists to first 2 neighbors\n",
    "    s = np.sum(np.log(dists2[0, :]/dists2[1, :]), axis=0)\n",
    "    ID = -2/(s/n)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idmind_mli(dists, D):\n",
    "    k = len(dists)\n",
    "    n = dists.shape[1]\n",
    "    nlogk = n*np.log(k)\n",
    "    rho = dists[0, :]/dists[k-1, :]\n",
    "    ll = np.zeros(D)\n",
    "    sum1 = np.sum(np.log(rho))\n",
    "    for d in range(1, D+1):\n",
    "        sum2 = np.sum(np.log(1-rho**d))\n",
    "        ll[d-1] = nlogk + n*np.log(d) + (d-1)*sum1 + (k-1)*sum2\n",
    "    ID = np.argmax(ll)+1\n",
    "    return ID\n",
    "\n",
    "\n",
    "def idtle(X, dists, epsilon=0.0001):\n",
    "\n",
    "    # X - matrix of nearest neighbors (k x d), sorted by distance\n",
    "    # dists - nearest-neighbor distances (k x 1), sorted\n",
    "    r = dists[0, -1]  # distance to k-th neighbor\n",
    "\n",
    "    # Boundary case 1: If $r = 0$, this is fatal, since the neighborhood would be degenerate.\n",
    "    if r == 0:\n",
    "        raise ValueError('All k-NN distances are zero!')\n",
    "    # Main computation\n",
    "    k = dists.shape[1]\n",
    "    V = squareform(pdist(X))\n",
    "    Di = np.tile(dists.T, (1, k))\n",
    "    Dj = Di.T\n",
    "    Z2 = 2*Di**2 + 2*Dj**2 - V**2\n",
    "    S = r * (((Di**2 + V**2 - Dj**2)**2 + 4*V**2 * (r**2 - Di**2))\n",
    "             ** 0.5 - (Di**2 + V**2 - Dj**2)) / (2*(r**2 - Di**2))\n",
    "    T = r * (((Di**2 + Z2 - Dj**2)**2 + 4*Z2 * (r**2 - Di**2))\n",
    "             ** 0.5 - (Di**2 + Z2 - Dj**2)) / (2*(r**2 - Di**2))\n",
    "    Dr = (dists == r).squeeze()  # handle case of repeating k-NN distances\n",
    "    S[Dr, :] = r * V[Dr, :]**2 / (r**2 + V[Dr, :]**2 - Dj[Dr, :]**2)\n",
    "    T[Dr, :] = r * Z2[Dr, :] / (r**2 + Z2[Dr, :] - Dj[Dr, :]**2)\n",
    "    # Boundary case 2: If $u_i = 0$, then for all $1\\leq j\\leq k$ the measurements $s_{ij}$ and $t_{ij}$ reduce to $u_j$.\n",
    "    Di0 = (Di == 0).squeeze()\n",
    "    T[Di0] = Dj[Di0]\n",
    "    S[Di0] = Dj[Di0]\n",
    "    # Boundary case 3: If $u_j = 0$, then for all $1\\leq j\\leq k$ the measurements $s_{ij}$ and $t_{ij}$ reduce to $\\frac{r v_{ij}}{r + v_{ij}}$.\n",
    "    Dj0 = (Dj == 0).squeeze()\n",
    "    T[Dj0] = r * V[Dj0] / (r + V[Dj0])\n",
    "    S[Dj0] = r * V[Dj0] / (r + V[Dj0])\n",
    "    # Boundary case 4: If $v_{ij} = 0$, then the measurement $s_{ij}$ is zero and must be dropped. The measurement $t_{ij}$ should be dropped as well.\n",
    "    V0 = (V == 0).squeeze()\n",
    "    np.fill_diagonal(V0, False)\n",
    "    T[V0] = r  # by setting to r, $t_{ij}$ will not contribute to the sum s1t\n",
    "    S[V0] = r  # by setting to r, $s_{ij}$ will not contribute to the sum s1s\n",
    "    # will subtract twice this number during ID computation below\n",
    "    nV0 = np.sum(V0)\n",
    "    # Drop T & S measurements below epsilon (V4: If $s_{ij}$ is thrown out, then for the sake of balance, $t_{ij}$ should be thrown out as well (or vice versa).)\n",
    "    TSeps = (T < epsilon) | (S < epsilon)\n",
    "    np.fill_diagonal(TSeps, 0)\n",
    "    nTSeps = np.sum(TSeps)\n",
    "    T[TSeps] = r\n",
    "    T = np.log(T/r)\n",
    "    S[TSeps] = r\n",
    "    S = np.log(S/r)\n",
    "    np.fill_diagonal(T, 0)  # delete diagonal elements\n",
    "    np.fill_diagonal(S, 0)\n",
    "    # Sum over the whole matrices\n",
    "    s1t = np.sum(T)\n",
    "    s1s = np.sum(S)\n",
    "    # Drop distances below epsilon and compute sum\n",
    "    Deps = dists < epsilon\n",
    "    nDeps = np.sum(Deps, dtype=int)\n",
    "    dists = dists[nDeps:]\n",
    "    s2 = np.sum(np.log(dists/r))\n",
    "    # Compute ID, subtracting numbers of dropped measurements\n",
    "    ID = -2*(k**2-nTSeps-nDeps-nV0) / (s1t+s1s+2*s2)\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
